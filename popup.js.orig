<<<<<<< HEAD
// Pre-fill the thread URL based on current tab
chrome.tabs.query({ active: true, currentWindow: true }, tabs => {
  const url = tabs[0]?.url || '';
  if (url.includes("showthread.php?threadid=")) {
    document.getElementById("start-url").value = url;
  }
});

document.getElementById("start-scrape").addEventListener("click", () => {
  const url = document.getElementById("start-url").value.trim();

  if (!url.includes("somethingawful.com/showthread.php?threadid=")) {
    alert("Invalid SA thread URL.");
    return;
  }

  chrome.runtime.sendMessage({ action: "start-scrape", url });
  document.getElementById("status").textContent = "Scraping started. Check debug console for progress.";
  document.getElementById("start-scrape").disabled = true;
});

chrome.runtime.onMessage.addListener((msg) => {
  if (msg.action === 'status') {
    document.getElementById('status').textContent = msg.msg;

    if (msg.msg.includes("complete")) {
      document.getElementById("start-scrape").disabled = false;
    }
  }
=======
/* TODO:
 *
 * Quote tweets aren't showing up, although I can probably access them.
 * Replies aren't showing up at all for some reason.
 * Make sure URLs within tweet content works.
 *
 * Expand tweet embeds to include images / videos from the tweet.
 *
 * Detect dead tweet links, and grab them and their pics/data off archive.org instead somehow.  Example of dead link: https://twitter.com/racheljulie/status/1245114069339852802?s=20
 *
 * Follow external non-twitter links and archive the complete .mhtml - too big?  Too hard?
 *
 * Without losing machine readability of the HTML files, make them human-consumable with infinite scroll (next/prev pages load into place when nearby, if they exist; remove excess loaded posts)
 *
 * In scraper, handle cases where clone.innerHTML needs sanitization, if/when testing ever encounters a live post containing HTML, possibly in a code block.
 *
 * Make sure during the final scrape that the poster ignore list is temporarily empty.
 *
 * Bugs:
 *
 * Intermittent: The scraper sometimes replaces blocks like these with just an img:
 * <span class="timg_container"><img src="https://i.kym-cdn.com/photos/images/newsfeed/001/777/149/a8c.gif" alt="" class="timg complete" border="0"><div class="note" title="Click to toggle">600x337</div></span>
 *
 * Intermittent pause/resume weirdness; may want to double check or redo pages near the pause point.
 */

document.addEventListener('DOMContentLoaded', () => {
  const startBtn = document.getElementById('startButton');
  const pauseBtn = document.getElementById('pauseButton');
  const resumeBtn = document.getElementById('resumeButton');
  const statusText = document.getElementById('status');
  const progressContainer = document.getElementById('progressContainer');
  const progressLabel = document.getElementById('progressLabel');
  const maxPagesInput = document.getElementById('maxPagesInput');

  let isRunning = false;
  let resumePage = null;

  function updateButtons() {
    const canResume = resumePage !== null;

    startBtn.disabled  = isRunning || isPaused;                 // can't Start while running or paused
    pauseBtn.disabled  = !isRunning;                            // only pause when running
    resumeBtn.disabled = isRunning || (!isPaused && !canResume);
  }


  // Initial load
  chrome.runtime.sendMessage({ command: 'getStatusAndResume' }, response => {
    isRunning = response?.isRunning || false;
    isPaused = response?.isPaused || false;
    resumePage = (typeof response?.resumePage === "number" && response.resumePage >= 0)
      ? response.resumePage
      : null;

    // Status + progress
    if (isRunning) {
      statusText.textContent = 'Scraping in progress...';
      progressContainer.style.display = 'block';
    } else if (isPaused) {
      statusText.textContent = 'Paused.';
      progressContainer.style.display = 'block';
    } else if (resumePage !== null) {
      statusText.textContent = `Can resume from page ${resumePage + 1}`;
      progressContainer.style.display = 'block';
    } else {
      statusText.textContent = 'Ready to start new archive';
      progressContainer.style.display = 'none';
    }

    updateButtons();
  });

  startBtn.addEventListener('click', () => {
    const maxPages = parseInt(maxPagesInput.value, 10) || 1;
    chrome.runtime.sendMessage({ command: 'start-scrape', maxPages });
    isRunning = true;
    updateButtons();
    progressContainer.style.display = 'block';
    statusText.textContent = 'Scraping started...';
    progressLabel.textContent = `0 / ${maxPages}`;
  });

  pauseBtn.addEventListener('click', () => {
    chrome.runtime.sendMessage({ command: 'pause' });
    isRunning = false;
    updateButtons();
    statusText.textContent = 'Paused.';
  });

  resumeBtn.addEventListener('click', () => {
    chrome.runtime.sendMessage({ command: 'resume' });
    isRunning = true;
    updateButtons();
    statusText.textContent = 'Resuming scraping...';
  });

  chrome.runtime.onMessage.addListener(msg => {
    if (msg.type === 'status') {
      statusText.textContent = msg.text;
    }
    if (msg.type === 'progressUpdate') {
      progressLabel.textContent = `${msg.page} / ${msg.max}`;
      progressContainer.style.display = 'block';
    }
  });

>>>>>>> 6e7b0fa (Initial commit; Scraping generally works but tweet text isn't being awaited, and other issues with the two tweet code paths not filling in fields.)
});

